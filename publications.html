<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Dr. Siddharth Roheda</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .paper-buttons {
            margin-top: 10px;
        }
        .paper-buttons button {
            display: inline-block;
            padding: 5px 10px;
            margin-right: 5px;
            background-color: #007bff;
            color: white;
            text-decoration: none;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        .paper-buttons button:hover {
            background-color: #0056b3;
        }
        .abstract {
            display: none;
            margin-top: 10px;
            padding: 10px;
            border-left: 3px solid #007bff;
            background-color: #f9f9f9;
        }
        .conference-logo {
            width: 100px;
            height: auto;
            vertical-align: middle;
            margin-right: 10px;
        }
    </style>
    <script>
        function toggleAbstract(id) {
            var abstract = document.getElementById(id);
            if (abstract.style.display === "none" || abstract.style.display === "") {
                abstract.style.display = "block";
            } else {
                abstract.style.display = "none";
            }
        }
    </script>
</head>
<body>

    <header>
        <h1>Publications</h1>
    </header>

    <section>
        <h2>Selected Publications</h2>
        
        <article>
            <h3><img src="cvpr2024-4.png" alt="XYZ Conference Logo" class="conference-logo"> MR-VNet: Media Restoration using Volterra Networks</h3>
            <p><strong>Authors:</strong> Siddharth Roheda, Amit Unde, Loay Rashid</p>
            <div class="paper-buttons">
                <button onclick="toggleAbstract('abstract1')">Abstract</button>
                <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Roheda_MR-VNet_Media_Restoration_using_Volterra_Networks_CVPR_2024_paper.pdf" target="_blank">Full Paper</a>
            </div>
            <div id="abstract1" class="abstract">
                <p>This research paper presents a novel class of restoration network architecture based on the Volterra series formulation. By incorporating non-linearity into the system response function through higher order convolutions instead of traditional activation functions, we introduce a general framework for image/video restoration. Through extensive experimentation, we demonstrate that our proposed architecture achieves state-of-the-art (SOTA) performance in the field of Image/Video Restoration. Moreover, we establish that the recently introduced Non-Linear Activation Free Network (NAF-NET) can be considered a special case within the broader class of Volterra Neural Networks. These findings highlight the potential of Volterra Neural Networks as a versatile and powerful tool for addressing complex restoration tasks in computer vision.</p>
            </div>
        </article>
        
        <article>
            <h3><img src="JMLR.png" alt="ABC Journal Logo" class="conference-logo"> Volterra Neural Networks (VNNs)</h3>
            <p><strong>Authors:</strong> Siddharth Roheda, Hamid Krim, Bo Jiang</p>
            <div class="paper-buttons">
                <button onclick="toggleAbstract('abstract2')">Abstract</button>
                <a href="https://www.jmlr.org/papers/volume25/21-1082/21-1082.pdf" target="_blank">Full Paper</a>
            </div>
            <div id="abstract2" class="abstract">
                <p>The importance of inference in Machine Learning (ML) has led to an explosive number of different proposals in ML, and particularly in Deep Learning. In an attempt to reduce the complexity of Convolutional Neural Networks, we propose a Volterra filter-inspired Network architecture. This architecture introduces controlled non-linearities in the form of interactions between the delayed input samples of data. We propose a cascaded implementation of Volterra Filtering so as to significantly reduce the number of parameters required to carry out the same classification task as that of a conventional Neural Network. We demonstrate an efficient parallel implementation of this Volterra Neural Network (VNN), along with its remarkable performance while retaining a relatively simpler and potentially more tractable structure. Furthermore, we show a rather sophisticated adaptation of this network to nonlinearly fuse the RGB (spatial) information and the Optical Flow (temporal) information of a video sequence for action recognition. The proposed approach is evaluated on UCF-101 and HMDB-51 datasets for action recognition, and is shown to outperform state of the art CNN approaches.</p>
            </div>
        </article>

         <article>
            <h3><img src="ICIP-2023.png" alt="ICIP Logo" class="conference-logo"> Fast Optimal Transport for Latent Domain Adaptation</h3>
            <p><strong>Authors:</strong> Siddharth Roheda, Ashkan Panahi, Hamid Krim</p>
            <div class="paper-buttons">
                <button onclick="toggleAbstract('abstract3')">Abstract</button>
                <a href="https://arxiv.org/pdf/2210.00479" target="_blank">Full Paper</a>
            </div>
            <div id="abstract3" class="abstract">
                <p>In this paper, we address the problem of unsupervised Domain Adaptation. The need for such an adaptation arises when the distribution of the target data differs from that which is used to develop the model and the ground truth information of the target data is unknown. We propose an algorithm that uses optimal transport theory with a verifiably efficient and implementable solution to learn the best latent feature representation. This is achieved by minimizing the cost of transporting the samples from the target domain to the distribution of the source domain.</p>
            </div>
        </article>
        
        <!-- Add more papers as needed -->
    </section>

    <a href="index.html">Back to Home</a>

</body>
</html>
